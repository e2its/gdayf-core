{
  "persistence": {
    "description": "Persistence layer parameters",
    "compress_json": {
      "description": "Enable or disable gzip compression of json files"
    }
  },
  "frameworks": {
    "description": "Framework specific parameters",
    "h2o": {
      "description": "H20.ai handler specific parameters",
      "conf": {
        "description": "H20.ai engine parameters",
        "download_dir": {
          "description": "relative path for pojo and mojo models download"
        },
        "url": {
          "description": "Server url: http://server:port"
        },
        "nthreads": {
          "description": "Number of CPUs"
        },
        "ice_root": {
          "description": "absolute path for H2O.ai ice logs engine"
        },
        "max_mem_size": {
          "description": "Max Memory size for H2O engine"
        },
        "start_h2o": {
          "description": "Enable/disable cluster automatic startup"
        },
        "debug": {
          "description": "Enable/disable debug mode"
        },
        "save_model": {
          "description": "model saving format: NATIVE supported"
        },
        "autosaved": {
          "description": "Enable/disable H2O.ai automatic model execution savings. True on multi-engine working mode"
        },
        "tolerance": {
          "description": "Regression tolerance threshold % in decinal format"
        },
        "enabled": {
          "description": "Enable/disable H2O.ai engine"
        },
        "min_rows_enabled": {
          "description": "Enable/disable min rows limit on models selection"
        },
        "max_cols_enabled": {
          "description": "Enable/disable max columns limit on models selection"
        },
        "train_balance_metric": {
          "description": "% rate in decimal format to define train metrics impact on accuracy combined metrics"
        },
        "validation_frame_ratio": {
          "description": "% rate in decimal format for training/validation dataset split work without cross-validation"
        },
        "validation_frame_threshold": {
          "description": "Limit value to work with cross-validation. Upper values of rows work with validation frame"
        },
        "anomaly_threshold": {
          "description": "tolerance values for anomalies detection",
          "columns": {
            "description": "% rate, in decimal format, mse tolerance for columns anomalies detection"
          },
          "global_mse": {
            "description": "% rate, in decimal format, mse tolerance for all dataset anomalies detection"
          }
        },
        "optimizable_scale_params": {
          "description": "List of H2O.ai model parameters initialisable based on problem scale "
        }
      },
      "models": {
        "model": {
          "description": "Model Name class on H2O.ai engine"
        },
        "id": {
          "description": "Not used"
        },
        "module": {
          "description": "Model package on H2O.ai engine"
        },
        "min_rows_applicability": {
          "description": "Min rows limit on models selection. 0 Disabled"
        },
        "max_cols_applicability": {
          "description": "Max columns limit on models selection. null Disable"
        },
        "enabled": {
          "description": "Enable/disable model selection"
        },
        "types": {
          "type": {
            "description": "binomial|multinomial|regression|clustering|anomalies|topology"
          },
          "active": {
            "description": "Enable/disable analysis selection"
          }
        },
        "parameters": {
          "base": {
            "description": "Specific base model parameters"
          },
          "effort": {
            "description": "Specific effort model parameters"
          },
          "repetible": {
            "description": "Specific model parameters for reproducibility"
          },
          "scoring": {
            "description": "Specific model parameters for internal scoring"
          },
          "stopping": {
            "description": "Specific model parameters for early stopping"
          },
          "xval": {
            "description": "Specific model parameters for cross-validation"
          },
          "sampling": {
            "description": "Specific model parameters for sampling"
          },
          "distribution": {
            "description": "Specific model parameters for distribution selection"
          },
          "learn": {
            "description": "Specific model parameters for learning rating"
          },
          "others": {
            "description": "Other model parameters"
          }
        }
      }
    },
    "spark": {
      "conf": {
        "description": "Apache Spark engine parameters",
        "download_dir": {
          "description": "Not used"
        },
        "master": {
          "description": "Server url: http://server:port"
        },
        "nthreads": {
          "description": "Numer of CPUs"
        },
        "spark_warehouse_dir": {
          "description": "absolute path for Apache Spark Warehouse Directory"
        },
        "spark.executor.memory": {
          "description": "Max Memory size for Spark workers"
        },
        "spark.driver.memory": {
          "description": "Max Memory size for Spark driver"
        },
        "start_spark": {
          "description": "Enable/disable cluster automatic startup"
        },
        "save_model": {
          "description": "model saving format: NATIVE supported"
        },
        "tolerance": {
          "description": "Regression tolerance threshold % in decinal format"
        },
        "enabled": {
          "description": "Enable/disable Apache Spark engine"
        },
        "min_rows_enabled": {
          "description": "Enable/disable min rows limit on models selection"
        },
        "max_cols_enabled": {
          "description": "Enable/disable max columns limit on models selection"
        },
        "train_balance_metric": {
          "description": "% rate in decimal format to define train metrics impact on accuracy combined metrics"
        },
        "validation_frame_ratio": {
          "description": "% rate in decimal format for training/validation dataset split work without cross-validation"
        },
        "nfolds": {
          "description": "Number od folds for Cross-validation"
        },
        "validation_frame_threshold": {
          "description": "Limit value to work with cross-validation. Upper values of rows work with validation frame"
        },
        "anomaly_threshold": {
          "description": "tolerance values for anomalies detection",
          "columns": {
            "description": "% rate, in decimal format, mse tolerance for columns anomalies detection"
          },
          "global_mse": {
            "description": "% rate, in decimal format, mse tolerance for all dataset anomalies detection"
          }
        },
        "optimizable_scale_params": {
          "description": "List of Apache Spark model parameters initialisable based on problem scale "
        }
      },
      "models": {
        "model": {
          "description": "Model Name class on Apache Spark engine"
        },
        "id": {
          "description": "Not used"
        },
        "module": {
          "description": "Model package on Apache Spark engine"
        },
        "min_rows_applicability": {
          "description": "Min rows limit on models selection. 0 Disabled"
        },
        "max_cols_applicability": {
          "description": "Max columns limit on models selection. null Disable"
        },
        "enabled": {
          "description": "Enable/disable model selection"
        },
        "types": {
          "type": {
            "description": "binomial|multinomial|regression|clustering|anomalies|topology"
          },
          "active": {
            "description": "Enable/disable analysis selection"
          }
        },
        "parameters": {
          "base": {
            "description": "Specific base model parameters"
          },
          "effort": {
            "description": "Specific effort model parameters"
          },
          "repetible": {
            "description": "Specific model parameters for reproducibility"
          },
          "scoring": {
            "description": "Specific model parameters for internal scoring"
          },
          "stopping": {
            "description": "Specific model parameters for early stopping"
          },
          "xval": {
            "description": "Specific model parameters for cross-validation"
          },
          "sampling": {
            "description": "Specific model parameters for sampling"
          },
          "distribution": {
            "description": "Specific model parameters for distribution selection"
          },
          "learn": {
            "description": "Specific model parameters for learning rating"
          },
          "others": {
            "description": "Other model parameters"
          }
        }
      }
    }
  },
  "logging": {
    "description": "logging layer parameters based on python logging package - logging â€” Logging facility for Python",
    "compatibility": "logging.config.dictConfig(config) - Configuration dictionary schema "
  },
  "storage": {
    "description": "storage specific parameters",
    "localfs": {
      "description": "local fs storage specific parameters",
      "value": {
        "description": "absolute path for local storage base path"
      },
      "type": {
        "description": "localfs"
      },
      "hash_value": {
        "description": "Hash key. initialized null"
      },
      "hash_type": {
        "description": "MD5|SHA256"
      }
    },
    "hdfs": {
      "description": "hdfs storage specific parameters",
      "value": {
        "description": "absolute path for hdfs engine storage base path"
      },
      "type": {
        "description": "hdfs"
      },
      "url": {
        "description": "url configuration for namenode web UI api access htttp protocol: http://server:port"
      },
      "uri": {
        "description": "uri configuration for namenode hdfs api access protocol: hdfs://server:port"
      },
      "hash_value": {
        "description": "Hash key. initialized null"
      },
      "hash_type": {
        "description": "MD5|SHA256"
      }
    },
    "mongoDB": {
      "description": "mongoDB NoSQL engine storage specific parameters",
      "value": {
        "description": "database"
      },
      "url": {
        "description": "database"
      },
      "port": {
        "description": "port"
      },
      "type": {
        "description": "mongoDB"
      },
      "hash_value": {
        "description": "Hash key. initialized null"
      },
      "hash_type": {
        "description": "MD5|SHA256"
      }
    },
    "primary_path": {
      "description": "Primary path for storage. localfs|hdfs|mongoDB"
    },
    "grants": {
      "description": "file grants in decimal format (755)",
      "load_path": {
        "description": "List of dictionary items indicating relative model storage"
      },
      "List-items": {
        "value": {
          "description": "relative path for models storage"
        },
        "type": "localfs|hdfs",
        "hash_value": {
          "description": "Hash key. initialized null"
        },
        "hash_type": {
          "description": "MD5|SHA256"
        }
      }
    },
    "log_path": {
      "description": "List of dictionary items indicating relative log storage",
      "List-items": {
        "value": {
          "description": "relative path for models storage"
        },
        "type": "localfs|hdfs",
        "hash_value": {
          "description": "Hash key. initialized null"
        },
        "hash_type": {
          "description": "MD5|SHA256"
        }
      }
    },
    "json_path": {
      "description": "List of dictionary items indicating relative storage json data for execution models",
      "List-items": {
        "value": {
          "description": "relative path for json storage"
        },
        "type": "localfs|hdfs|mongoDB",
        "hash_value": {
          "description": "Hash key. initialized null"
        },
        "hash_type": {
          "description": "MD5|SHA256"
        }
      }
    }
  },
  "normalizer": {
    "description": "Normalization specific parameters",
    "minimal_normalizations_enabled": {
      "description": "Enable/Disable minimal set of normalizations"
    },
    "non_minimal_normalizations_enabled": {
      "description": "Enable/Disable extended set of normalizations"
    },
    "manage_on_train_errors": {
      "description": "Enable/Disable automatic fulfillment of missing values on train datasets"
    },
    "base_normalization_enabled": {
      "description": "Enable/Disable base normalization from String to Factor"
    },
    "exclusion_missing_threshold": {
      "description": "% rate in decimal format to define column missing value exclusion factor"
    },
    "clustering_standardize_enabled": {
      "description": "Enable/Disable standardize normalization for clustering"
    },
    "standardize_enabled": {
      "description": "Enable/Disable standardize normalization"
    },
    "std_threshold": {
      "description": "% rate in decimal format to define standardize normalization tolerance to appliance"
    },
    "special_spark_naive_offset": {
      "description": "Multiplication factor for NaiveBayes offset application on Spark - Only positive number matrix. Recommended 2.0"
    },
    "datetime_columns_management": {
      "description": "Datetime columns management. Conversion to independent numeric columns",
      "enable": {
        "description": "Enable/Disable datetime conversion"
      },
      "filter": {
        "description": [
          "day",
          "month",
          "year",
          "weekday",
          "weeknumber",
          "hour",
          "minute",
          "second",
          "microsecond"
        ]
      },
      "ignore_original": {
        "description": "Enable/Disable datetime original column drop"
      }
    }
  },
  "optimizer": {
    "description": "Optimizer specific parameters",
    "adviser_classpath": {
      "description": "Package classpath for optimizer class"
    },
    "adviser_class": {
      "description": "Class name for optimizer class"
    },
    "adviser_L2_wide": {
      "description": "Number of model to be taken in account for optimization on level 2"
    },
    "adviser_normal_wide": {
      "description": "Number of model to be taken in account for optimization on level > 2"
    },
    "AdviserStart_rules": {
      "common": {
        "multi_limit": {
          "description": "% rate in decimal format to determine when apply multinomial analysis instead regression analysis"
        },
        "multi_limit": {
          "description": "max cardinality in natural format to determine when apply multinomial analysis instead regression analysis"
        }
      },
      "h2o": {
        "description": "Optimizer H2O.ai engine specific parameters",
        "nfold_limit": {
          "description": "Maximum limit in folder number for Cross-validation optimization"
        },
        "min_rows_limit": {
          "description": "Minimum limit in leaf rows prediction on Decision tree based analysis"
        },
        "cols_breakdown": {
          "description": "Number of columns established for L_BFGS application on GLM models"
        },
        "nfold_increment": {
          "description": "increment value for cross-validation optimization"
        },
        "min_rows_increment": {
          "description": "divisor value for min_rows optimization"
        },
        "max_interactions_rows_breakdown": {
          "description": "divisor value for initial iteration optimization on GLM models"
        },
        "max_interactions_increment": {
          "description": "increment value for iterations optimization on GLM based analysis"
        },
        "max_depth_increment": {
          "description": "multiplicative factor value for depth on DT based analysis"
        },
        "ntrees_increment": {
          "description": "multiplicative factor value for number of trees on DT based analysis"
        },
        "dpl_rcount_limit": {
          "description": "Upper limit rowcount value used on level 2 optimization for neurons on hidden layers calculous"
        },
        "dpl_divisor": {
          "description": "divisor value used on level 2 optimization for neurons on hidden layers calculous"
        },
        "h_dropout_ratio": {
          "description": "Deep learning dropout ratio"
        },
        "epochs_increment": {
          "description": "multiplicative factor value for epochs on DL based models"
        },
        "deeper_increment": {
          "description": "multiplicative factor value for Hidden layers on DL based models"
        },
        "wider_increment": {
          "description": "multiplicative factor value for neurons x hidden layer on DL based models"
        },
        "dpl_min_batch_size": {
          "description": "Minimum limit in batch size on DL based analysis"
        },
        "dpl_batch_divisor": {
          "description": "Not used"
        },
        "dpl_batch_reduced_divisor": {
          "description": "divisor factor value for batch size on DL based models"
        },
        "learning_conf": {
          "description": "List of dict() items for Learning parameters for GBT",
          "item-List": {
            "learn": {
              "description": "Learning rate"
            },
            "improvement": {
              "description": "improvement rate"
            }
          }
        },
        "rho_conf": {
          "description": "List of dict() items for Learning parameters for DL",
          "item-List": {
            "learn": {
              "description": "Learning rate"
            },
            "improvement": {
              "description": "improvement rate"
            }
          }
        },
        "nv_laplace": {
          "description": "List of values for laplace on Naive Bayes Models"
        },
        "nv_min_prob": {
          "description": "List of values of minimal probability for laplace on Naive Bayes Models"
        },
        "nv_min_sdev": {
          "description": "List of values of minimal standard deviation for laplace on Naive Bayes Models"
        },
        "nv_improvement": {
          "description": "% rate in decimal format of improvement on Naive Bayes Models"
        },
        "nv_divisor": {
          "description": "% rate in decimal format of negative improvement on Naive Bayes Models"
        },
        "clustering_increment": {
          "description": "multiplicative factor value for iterations in clusteriing based models"
        }
      },
      "spark": {
        "description": "Optimizer Apache Spark engine specific parameters",
        "min_rows_limit": {
          "description": "Minimum limit in leaf rows prediction on Decision tree based analysis"
        },
        "min_rows_increment": {
          "description": "divisor value for min_rows optimization"
        },
        "max_interactions_increment": {
          "description": "Upper limit value for iterations optimization"
        },
        "interactions_increment": {
          "description": "increment value for iterations optimization"
        },
        "max_depth_increment": {
          "description": "multiplicative factor value for depth on DT based analysis"
        },
        "ntrees_increment": {
          "description": "multiplicative factor value for number of trees on DT based analysis"
        },
        "aggregationDepth_increment": {
          "description": "multiplicative factor value for aggregationDepth on DT based analysis"
        },
        "stepSize": {
          "description": "List of dict() items for Learning parameters for GBT",
          "item-List": {
            "learn": {
              "description": "Learning rate"
            }
          }
        },
        "regParam": {
          "description": "List of dict() items for lambda parameter with elastic net regularization for GLM models",
          "item-List": {
            "value": {
              "description": "regParam (lambda) "
            }
          }
        },
        "elastic_variation": {
          "description": "% rate in decimal format of elasticNetParam (alpha) parameter with elastic net regularization for GLM models"
        },
        "nv_smoothing": {
          "description": "List of dict() items for smooth factor for Naive Bayes models",
          "item-List": {
            "value": {
              "description": "smoothing factor value"
            }
          }
        },
        "nv_improvement": {
          "description": "% rate in decimal format of improvement on Naive Bayes Models"
        },
        "nv_divisor": {
          "description": "% rate in decimal format of negative improvement on Naive Bayes Models"
        },
        "initstep_increment": {
          "description": "Not used"
        },
        "clustering_increment": {
          "description": "multiplicative factor value for iterations in clusteriing based models"
        }
      }
    },
    "common": {
      "description": "Common parameters for optimization",
      "base_increment": {
        "description": "Increment rate for problem size scale. realted to specific frameworks parameter -optimizable_scale_params-",
        "small": {
          "base": {
            "description": "Number of rows defining small size problem"
          },
          "increment": {
            "description": "multiplicative factor for optimizable_scale_params"
          }
        },
        "medium": {
          "base": {
            "description": "Number of rows defining medium size problem"
          },
          "increment": {
            "description": "multiplicative factor for optimizable_scale_params"
          }
        },
        "large": {
          "base": {
            "description": "Number of rows defining large size problem"
          },
          "increment": {
            "description": "multiplicative factor for optimizable_scale_params"
          }
        }
      }
    }
  },
  "dfmetadata": {
    "description": "DFmetadata specific parameters",
    "correlation_threshold": {
      "description": "% rate in decimal format to determine correlated values. abs(correlation Value) >= correlation_threshold"
    },
    "cardinality_limit": {
      "description": "Limit of maximum column cardinality without bucketed histogram"
    }
  },
  "common": {
    "version": {
      "description": "Product version"
    },
    "test_frame_ratio": {
          "description": "% split in decimal mode for test Dataframe"
    },
    "workflow_execution_dir": {
          "description": "relative path for workflow csv dataset"
        },
    "minimal_test_split": {
      "description": "Minimal amount of data to establish a primary dataframe split on test"
    }
  }
}
