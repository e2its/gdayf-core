version: '3.7'
networks:
  gdayf:
    name: gdayf
    external: true

services:
  unbuntu-mongodb:
    image: e2its/ubuntu-mongodb
    container_name: mongodb
    networks:
      - gdayf
    ports: 
      - 27017:27017
    volumes:  
      - /home/e2its/docker/volumes/mongodb/data/configdb:/data/configdb
      - /home/e2its/docker/volumes/mongodb/data/db:/data/db
    domainname: cluster.e2its.com
    hostname: unbuntu-mongodb
  ubuntu-h2o-1:
    image: e2its/ubuntu-h2o:base.3.30.0.1
    container_name: h2o-server-1
    networks:
      - gdayf
    ports: 
      - 54321:54321
    command: nohup bash -c "/usr/bin/java -Xmx2g -jar /root/h2o/h2o.jar -name gdayf -nthreads 3" > /root/h2o/h2o.logs
    deploy:
      resources:
        limits:
          cpus: '3.0'
          memory: 2g
    domainname: cluster.e2its.com
    hostname: ubuntu-h2o-1
  ubuntu-h2o-2:
    image: e2its/ubuntu-h2o:base.3.30.0.1
    container_name: h2o-server-2
    networks:
      - gdayf
    ports: 
      - 54322:54321
    command: nohup bash -c "/usr/bin/java -Xmx2g -jar /root/h2o/h2o.jar -name  gdayf -nthreads 2" > /root/h2o/h2o.logs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2g
    domainname: cluster.e2its.com
    hostname: ubuntu-h2o-2
  ubuntu-h2o-3:
    image: e2its/ubuntu-h2o:base.3.30.0.1
    container_name: h2o-server-3
    networks:
      - gdayf
    ports: 
      - 54323:54321
    command: nohup bash -c "/usr/bin/java -Xmx2g -jar /root/h2o/h2o.jar -name  gdayf -nthreads 2" > /root/h2o/h2o.logs
    deploy:
      resources:
       limits:
          cpus: '2.0'
          memory: 2g
    domainname: cluster.e2its.com
    hostname: ubuntu-h2o-3
  namenode:
    image: bde2020/hadoop-namenode:1.1.0-hadoop2.8-java8
    container_name: namenode
    volumes:
      - /home/e2its/docker/volumes/hadoop-hdfs/data/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=gdayf-hadoop
    env_file:
      - /home/e2its/docker/scripts/env/hadoop-hive.env
    networks:
      - gdayf
    ports:
      - 50070:50070
    domainname: cluster.e2its.com
    hostname: namenode
  datanode:
    image: bde2020/hadoop-datanode:1.1.0-hadoop2.8-java8
    container_name: datanode
    depends_on: 
      - namenode
    volumes:
      - /home/e2its/docker/volumes/hadoop-hdfs/data/datanode:/hadoop/dfs/data
    env_file:
      - /home/e2its/docker/scripts/env/hadoop-hive.env
    networks:
      - gdayf
    ports:
      - 50075:50075
      - 8020:8020
    domainname: cluster.e2its.com
    hostname: datanode
  hive-server:
    image: bde2020/hive:2.1.0-postgresql-metastore
    container_name: hive-server
    env_file: 
      - /home/e2its/docker/scripts/env/hadoop-hive.env
    environment:
      - "HIVE_CORE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-metastore/metastore"
    ports:   
      - "10000:10000"
    domainname: cluster.e2its.com
    hostname: hive-server
  hive-metastore:
    image: bde2020/hive:2.1.0-postgresql-metastore
    container_name: hive-metastore
    env_file:
      - /home/e2its/docker/scripts/env/hadoop-hive.env
    networks:
      - gdayf
    command: /opt/hive/bin/hive --service metastore
    domainname: cluster.e2its.com
    hostname: hive-metastore
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.1.0
    container_name:  hive-metastore-postgresql
    networks:
      - gdayf
    env_file:
      - /home/e2its/docker/scripts/env/hadoop-hive.env
    domainname: cluster.e2its.com
    hostname: hive-metastore-postgresql
  spark-master:
    image: e2its/ubuntu-spark:2.4.5
    command: /usr/sbin/start-master
    container_name: spark-master
    networks:
      - gdayf
    ports:
      - 8080:8080
      - 7077:7077
    env_file:
      - /home/e2its/docker/scripts/env/hadoop-hive.env
    environment:
      - SPARK_NO_DAEMONIZE=true
    domainname: cluster.e2its.com
    hostname: spark-master
  spark-worker-1:
    image: e2its/ubuntu-spark:2.4.5
    command: "/usr/sbin/start-slave spark://spark-master:7077"
    container_name: spark-worker-1
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_NO_DAEMONIZE=true
    networks:
      - gdayf
    ports:
      - "8081:8081"
    env_file:
      - /home/e2its/docker/scripts/env/hadoop-hive.env
    deploy:
      resources:
       limits:
          cpus: '3.0'
          memory: 2g
    domainname: cluster.e2its.com
    hostname: spark-worker-1
  spark-worker-2:
    image: e2its/ubuntu-spark:2.4.5
    command: "/usr/sbin/start-slave spark://spark-master:7077"
    container_name: spark-worker-2
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_NO_DAEMONIZE=true
    networks:
      - gdayf
    ports:
      - "8082:8081"
    env_file:
      - /home/e2its/docker/scripts/env/hadoop-hive.env
    deploy:
      resources:
       limits:
          cpus: '1.5'
          memory: 2g
    domainname: cluster.e2its.com
    hostname: spark-worker-2 
  spark-worker-3:
    image: e2its/ubuntu-spark:2.4.5
    command: "/usr/sbin/start-slave spark://spark-master:7077"
    container_name: spark-worker-3
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_NO_DAEMONIZE=true
    networks:
      - gdayf
    ports:
      - "8083:8081"      
    env_file:
      - /home/e2its/docker/scripts/env/hadoop-hive.env
    deploy:
      resources:
       limits:
          cpus: '1.5'
          memory: 2g
    domainname: cluster.e2its.com
    hostname: spark-worker-3
  spark-notebook:
    image: e2its/ubuntu-spark:2.4.5
    env_file:
      - /home/e2its/docker/scripts/env/hadoop-hive.env
    networks:
      - gdayf
    ports:
      - 9001:9001
    domainname: cluster.e2its.com
    hostname: spark-notebook
  hue:
    image: bde2020/hdfs-filebrowser:3.11
    container_name: hue
    networks:
      - gdayf
    ports:
      - 8088:8088
    environment:
      - NAMENODE_HOST=namenode
    env_file:
      - /home/e2its/docker/scripts/env/hadoop-hive.env
    domainname: cluster.e2its.com
    hostname: hue
